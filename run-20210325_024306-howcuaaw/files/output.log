===> Building network [SRFBN]...
wandb: Network error resolved after 0:00:39.288089, resuming normal operation.
==> Initializing the network using [kaiming]
initialization method [kaiming]
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
initializing [Conv2d] ...
==================================================
===> Network Summary

SRFBN(
  (sub_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))
  (conv_in): Sequential(
    (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PReLU(num_parameters=1)
  )
  (feat_in): Sequential(
    (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): PReLU(num_parameters=1)
  )
  (block): FeedbackBlock(
    (compress_in): Sequential(
      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): PReLU(num_parameters=1)
    )
    (convBlocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (5): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): PReLU(num_parameters=1)
      )
    )
    (diconvBlocks_s): ModuleList(
      (0): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (1): PReLU(num_parameters=1)
      )
      (5): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (1): PReLU(num_parameters=1)
      )
    )
    (diconvBlocks_l): ModuleList(
      (0): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
        (1): PReLU(num_parameters=1)
      )
      (5): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
        (1): PReLU(num_parameters=1)
      )
    )
    (fusionBlocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (5): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
    )
    (convtranBlocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
    )
    (diconvtranBlocks_s): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
    )
    (diconvtranBlocks_l): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (1): Sequential(
        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (2): Sequential(
        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (3): Sequential(
        (0): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
      (4): Sequential(
        (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): PReLU(num_parameters=1)
      )
    )
    (compress_out): Sequential(
      (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): PReLU(num_parameters=1)
    )
  )
  (conv_out): Sequential(
    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (add_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))
)

Network structure: [DataParallel - SRFBN], with parameters: [1,043,846]
==================================================
===> Solver Initialized : [SRSolver] || Use CL : [True] || Use GPU : [True]
optimizer:  Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)
lr_scheduler milestones: Counter({200: 1, 400: 1, 600: 1, 800: 1})   gamma: 0.500000
===> Start Train
==================================================
Method: SRFBN || Quality: 10 || Epoch Range: (1 ~ 1000)

===> Training Epoch: [1/1000]...  Learning Rate: 0.000100
Epoch: [1/1000]:   0%|          | 0/100 [00:00<?, ?it/s]Epoch: [1/1000]:   0%|          | 0/100 [00:44<?, ?it/s]
Traceback (most recent call last):
  File "/home/gyq/share/gyq/program/SRFBN_CVPR19_fix_2/train.py", line 143, in <module>
    main()
  File "/home/gyq/share/gyq/program/SRFBN_CVPR19_fix_2/train.py", line 73, in main
    iter_loss = solver.train_step()
  File "/home/gyq/share/gyq/program/SRFBN_CVPR19_fix_2/solvers/SRSolver.py", line 133, in train_step
    outputs = self.model(split_LR)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 155, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 165, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 85, in parallel_apply
    output.reraise()
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 60, in _worker
    output = module(*input, **kwargs)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gyq/share/gyq/program/SRFBN_CVPR19_fix_2/networks/srfbn_arch.py", line 149, in forward
    h = self.block(x_c)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gyq/share/gyq/program/SRFBN_CVPR19_fix_2/networks/srfbn_arch.py", line 83, in forward
    LD_D_l = self.diconvtranBlocks_l[idx - 1](LD_D_l)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 988, in forward
    return F.prelu(input, self.weight)
  File "/home/gyq/software/Anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1319, in prelu
    return torch.prelu(input, weight)
RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 10.92 GiB total capacity; 10.19 GiB already allocated; 3.69 MiB free; 10.19 GiB reserved in total by PyTorch)

